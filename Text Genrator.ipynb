{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d03ccf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a26431b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "filename = \"sample.txt\"\n",
    "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
    "raw_text = raw_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ef1dcbeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there were four of us - george, and william samuel harris, and myself, and\n",
      "montmorency. we were sitting in my room, smoking, and talking about how bad\n",
      "we were - bad from a medical point of view i mean, of course.\n",
      "we were all feeling seedy, and we wer\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the first 250 characters in text\n",
    "print(raw_text[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3ca36ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 unique characters\n"
     ]
    }
   ],
   "source": [
    "# The unique characters in the file\n",
    "vocab = sorted(set(raw_text))\n",
    "print(f'{len(vocab)} unique characters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "48e10dd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_texts = ['abcdefg', 'xyz']\n",
    "\n",
    "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d28d57af",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_from_chars = tf.keras.layers.StringLookup(\n",
    "    vocabulary=list(vocab), mask_token=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dcc3e9d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[16, 17, 18, 19, 20, 21, 22], [39, 40, 41]]>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = ids_from_chars(chars)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8ef3563a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars_from_ids = tf.keras.layers.StringLookup(\n",
    "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fa01292b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = chars_from_ids(ids)\n",
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1ccc057c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'abcdefg', b'xyz'], dtype=object)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.reduce_join(chars, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "402c8fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_from_ids(ids):\n",
    "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3af502aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(18789,), dtype=int64, numpy=array([35, 23, 20, ..., 20, 19, 10], dtype=int64)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ids = ids_from_chars(tf.strings.unicode_split(raw_text, 'UTF-8'))\n",
    "all_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ab382f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6c797427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      "e\n",
      " \n",
      "w\n",
      "e\n",
      "r\n",
      "e\n"
     ]
    }
   ],
   "source": [
    "for ids in ids_dataset.take(10):\n",
    "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2586bc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4559a5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b't' b'h' b'e' b'r' b'e' b' ' b'w' b'e' b'r' b'e' b' ' b'f' b'o' b'u'\n",
      " b'r' b' ' b'o' b'f' b' ' b'u' b's' b' ' b'-' b' ' b'g' b'e' b'o' b'r'\n",
      " b'g' b'e' b',' b' ' b'a' b'n' b'd' b' ' b'w' b'i' b'l' b'l' b'i' b'a'\n",
      " b'm' b' ' b's' b'a' b'm' b'u' b'e' b'l' b' ' b'h' b'a' b'r' b'r' b'i'\n",
      " b's' b',' b' ' b'a' b'n' b'd' b' ' b'm' b'y' b's' b'e' b'l' b'f' b','\n",
      " b' ' b'a' b'n' b'd' b'\\n' b'm' b'o' b'n' b't' b'm' b'o' b'r' b'e' b'n'\n",
      " b'c' b'y' b'.' b' ' b'w' b'e' b' ' b'w' b'e' b'r' b'e' b' ' b's' b'i'\n",
      " b't' b't' b'i'], shape=(101,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for seq in sequences.take(1):\n",
    "  print(chars_from_ids(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a3c4bced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'there were four of us - george, and william samuel harris, and myself, and\\nmontmorency. we were sitti'\n",
      "b'ng in my room, smoking, and talking about how bad\\nwe were - bad from a medical point of view i mean, '\n",
      "b'of course.\\nwe were all feeling seedy, and we were getting quite nervous about it. harris\\nsaid he felt'\n",
      "b' such extraordinary fits of giddiness come over him at times, that he\\nhardly knew what he was doing; '\n",
      "b'and then george said that he had fits of giddiness\\ntoo, and hardly knew what he was doing. with me, i'\n"
     ]
    }
   ],
   "source": [
    "for seq in sequences.take(5):\n",
    "  print(text_from_ids(seq).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "aad6bb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(sequence):\n",
    "    input_text = sequence[:-1]\n",
    "    target_text = sequence[1:]\n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f321a104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
       " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_input_target(list(\"Tensorflow\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "75a9ec3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f4aeab4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input : b'there were four of us - george, and william samuel harris, and myself, and\\nmontmorency. we were sitt'\n",
      "Target: b'here were four of us - george, and william samuel harris, and myself, and\\nmontmorency. we were sitti'\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in dataset.take(1):\n",
    "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
    "    print(\"Target:\", text_from_ids(target_example).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ddd6482a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = (\n",
    "    dataset\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e0091b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the vocabulary in StringLookup Layer\n",
    "vocab_size = len(ids_from_chars.get_vocabulary())\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d00cabb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "    super().__init__(self)\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True)\n",
    "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "  def call(self, inputs, states=None, return_state=False, training=False):\n",
    "    x = inputs\n",
    "    x = self.embedding(x, training=training)\n",
    "    if states is None:\n",
    "      states = self.gru.get_initial_state(x)\n",
    "    x, states = self.gru(x, initial_state=states, training=training)\n",
    "    x = self.dense(x, training=training)\n",
    "\n",
    "    if return_state:\n",
    "      return x, states\n",
    "    else:\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "df6875e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f3b4a44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 42) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4b454104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     multiple                  10752     \n",
      "                                                                 \n",
      " gru_1 (GRU)                 multiple                  3938304   \n",
      "                                                                 \n",
      " dense_1 (Dense)             multiple                  43050     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,992,106\n",
      "Trainable params: 3,992,106\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "95d70253",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ba7f5d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([40, 34, 18,  3, 36, 14, 14, 30,  2, 17,  5, 19, 25,  7, 41, 25, 27,\n",
       "       11, 17, 34, 16,  7,  9, 28, 14,  7, 35, 15, 28, 35, 21, 33,  5,  1,\n",
       "        0, 21,  7, 35, 14,  2,  9, 39, 32,  7, 37, 22, 17, 38, 12,  3, 30,\n",
       "       34, 34,  3, 38,  7, 11,  4, 38, 16, 33, 19,  5,  9, 29,  7, 32, 22,\n",
       "       23, 23, 34, 20,  8,  9, 14, 30,  4, 14, 16, 41, 35, 14, 20, 30, 39,\n",
       "        1, 23,  0, 38, 38, 10,  6, 19, 33, 11, 10,  7,  4, 30, 31],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2aa7e0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      " b'rp every night. and don\\'t stuff up your head with things you\\ndon\\'t understand.\"\\ni followed the direc'\n",
      "\n",
      "Next Char Predictions:\n",
      " b'ysc!u;;o b\\'dj)zjl1bsa)-m;)t?mtfr\\'\\n[UNK]f)t; -xq)vgbw6!oss!w)1\"ward\\'-n)qghhse,-;o\";azt;eox\\nh[UNK]ww.(dr1.)\"op'\n"
     ]
    }
   ],
   "source": [
    "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
    "print()\n",
    "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c2e012b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ae9b04c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 100, 42)  # (batch_size, sequence_length, vocab_size)\n",
      "Mean loss:         tf.Tensor(3.7383184, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"Mean loss:        \", example_batch_mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dc6891ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.02726"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.exp(example_batch_mean_loss).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dc7eb4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ff8dda1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a03cbfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c93edb2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 7s 2s/step - loss: 3.7198\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 5s 2s/step - loss: 3.5697\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 5s 2s/step - loss: 4.7335\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 5s 2s/step - loss: 3.5233\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 5s 2s/step - loss: 3.5701\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 5s 2s/step - loss: 3.5697\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 4s 2s/step - loss: 3.5508\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 4s 2s/step - loss: 3.5198\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 4s 2s/step - loss: 3.4672\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 4s 2s/step - loss: 3.3870\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 4s 2s/step - loss: 3.2569\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 5s 2s/step - loss: 3.1039\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 5s 2s/step - loss: 3.0279\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 5s 2s/step - loss: 2.9258\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 5s 3s/step - loss: 2.9220\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 5s 2s/step - loss: 2.9099\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 5s 2s/step - loss: 2.8895\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 5s 2s/step - loss: 2.8371\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 5s 2s/step - loss: 2.7982\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 5s 2s/step - loss: 2.7753\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3ffb1240",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneStep(tf.keras.Model):\n",
    "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
    "    super().__init__()\n",
    "    self.temperature = temperature\n",
    "    self.model = model\n",
    "    self.chars_from_ids = chars_from_ids\n",
    "    self.ids_from_chars = ids_from_chars\n",
    "\n",
    "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
    "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
    "    sparse_mask = tf.SparseTensor(\n",
    "        # Put a -inf at each bad index.\n",
    "        values=[-float('inf')]*len(skip_ids),\n",
    "        indices=skip_ids,\n",
    "        # Match the shape to the vocabulary\n",
    "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
    "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "  @tf.function\n",
    "  def generate_one_step(self, inputs, states=None):\n",
    "    # Convert strings to token IDs.\n",
    "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
    "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "\n",
    "    # Run the model.\n",
    "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
    "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
    "                                          return_state=True)\n",
    "    # Only use the last prediction.\n",
    "    predicted_logits = predicted_logits[:, -1, :]\n",
    "    predicted_logits = predicted_logits/self.temperature\n",
    "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
    "    predicted_logits = predicted_logits + self.prediction_mask\n",
    "\n",
    "    # Sample the output logits to generate token IDs.\n",
    "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "\n",
    "    # Convert from token ids to characters\n",
    "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
    "\n",
    "    # Return the characters and model state.\n",
    "    return predicted_chars, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b93e1313",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "be3262f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEORGE:lhss wmadk iushnd\"dewno!ked i, te hhh aeo trhe aad hrt ee anisel ol hay chn t aer n ta o,fawha awoo oy se zysf nua ito ouom ihcant a,dde orhled nt toot hnprodeut cewheen tes\n",
      "mgbrehaedt utt ah iinaese\n",
      "hcsee ihoi puiue\n",
      "cfl,\n",
      "atyv nogiey veni'wiinsteed auhi tle utheo s tlhelhwere ao eead omg tre ted e eh, aees oit , ie\n",
      "ne sa tschhlit hebn hhe eeo ns hnindt morkokhed as tho telne eho\n",
      "n cee ngni lee mcfesrhialsig oe ltyte ui xthe g temole ipaw as rilonelte ohde wie net ie toaadye asphtifdshati ld theem assee io dd\n",
      "e a,eshe,\n",
      "uany th iasre dt hrsun id mea heorcmkpe adcd gf thceewgine ebndmlwbtehemouhtaeroe woeleualen-i ma ot e.t co ee h uetny te te t hhe\n",
      " ou sokulwrtrmo,y m hnwteb, me ntho ma tdheoeees sise, ee otiee e oaft tte o ue d  er se t tit hei goce wat d hai asa  ltt hsednfe tsed ce ithfw ouetd gidsn,t heo leth satorr e mnn hgwt w e at a dtechceerpheey wee s e t;e  auos iou  ontoo thtotetr odne lod o s addaui,e eofr laeedt hhoi nege, sheny\n",
      "tvn toi ethottdteased noa ednot man me on bo t \n",
      "\n",
      "________________________________________________________________________________\n",
      "\n",
      "Run time: 4.0649094581604\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant(['GEORGE:'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(1000):\n",
    "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "  result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
    "print('\\nRun time:', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fc8065",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
